{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Behavioral Cloning\n",
    "### Lukasz Uszko, June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This report describes my implementation of a convolutional neural network (CNN) to predict steering angles from a set of training images acquired from a driving simulator. The CNN is a slightly modified Keras implementation of this paper from NVIDIA Corporation. The trained model successfully steered the simulated car around track-1 of the beta-simulator provided as part of this project.\n",
    "\n",
    "This report describes results from training performed using the sample dataset provided by Udacity and my own training set from tracks 1 and 2 which I acquired by manually driving the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "The following files accompany this report:\n",
    "\n",
    "* `model.py`: Script used to create and train the CNN. This report describes how the model was developed and trained.\n",
    "* `model.h5`: The trained model, created by the above script.\n",
    "* `drive.py`: Script used to drive the car using the trained model above.\n",
    "## Usage\n",
    "* Open a terminal and start the simulator: ./beta_simulator.x86_64\n",
    "* Open another terminal and run the following to drive the simulated car autonomously: python drive.py model.h5\n",
    "* The simulated car will now start moving. Verify that the car stays on the road at all times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and project globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Some globals\n",
    "DATA_FOLDER_PATH = './data'\n",
    "A4_PORTRAIT = (8.27, 11.69)\n",
    "A4_LANDSCAPE = A4_PORTRAIT[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Development\n",
    "### Loading the training set\n",
    "I first examined the organisation of training data which consisted of a csv file and a set of images. The following code loads and prints out some basic information about training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG/center_2016_12_01_13_30_48_287.jpg'\n",
      " 'IMG/center_2016_12_01_13_30_48_404.jpg'\n",
      " 'IMG/center_2016_12_01_13_31_12_937.jpg' ...,\n",
      " 'IMG/center_2019_06_28_17_16_51_129.jpg'\n",
      " 'IMG/center_2019_06_28_17_16_51_211.jpg'\n",
      " 'IMG/center_2019_06_28_17_16_51_333.jpg']\n",
      "[' IMG/left_2016_12_01_13_30_48_287.jpg'\n",
      " ' IMG/left_2016_12_01_13_30_48_404.jpg'\n",
      " ' IMG/left_2016_12_01_13_31_12_937.jpg' ...,\n",
      " 'IMG/left_2019_06_28_17_16_51_129.jpg'\n",
      " 'IMG/left_2019_06_28_17_16_51_211.jpg'\n",
      " 'IMG/left_2019_06_28_17_16_51_333.jpg']\n",
      "[' IMG/right_2016_12_01_13_30_48_287.jpg'\n",
      " ' IMG/right_2016_12_01_13_30_48_404.jpg'\n",
      " ' IMG/right_2016_12_01_13_31_12_937.jpg' ...,\n",
      " 'IMG/right_2019_06_28_17_16_51_129.jpg'\n",
      " 'IMG/right_2019_06_28_17_16_51_211.jpg'\n",
      " 'IMG/right_2019_06_28_17_16_51_333.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Read driving_log data\n",
    "csv_file_path = os.path.join(DATA_FOLDER_PATH,'driving_log.csv')\n",
    "samples = []\n",
    "with open(csv_file_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "csvfile = pd.read_csv(csv_file_path)\n",
    "print(csvfile.center.values)\n",
    "print(csvfile.left.values)\n",
    "print(csvfile.right.values)\n",
    "\n",
    "\n",
    "# Split data\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "def load_image(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set augmentation\n",
    "\n",
    "During training, you want to feed the left and right camera images to your model as if they were coming from the center camera. This way, you can teach your model how to steer if the car drifts off to the left or the right.\n",
    "\n",
    "Figuring out how much to add or subtract from the center angle will involve some experimentation.\n",
    "\n",
    "During prediction (i.e. \"autonomous mode\"), you only need to predict with the center camera image.\n",
    "\n",
    "It is not necessary to use the left and right images to derive a successful model. Recording recovery driving from the sides of the road is also effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
